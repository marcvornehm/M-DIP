{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sigpy.mri\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from dip import evaluate, fft_np, models, mri, plotting\n",
    "from dip.dataset import MRDDataset, PhantomDataset\n",
    "from dip.lps import LowRankPlusSparse\n",
    "from dip.mdip import MDIP\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "if 'params' not in locals():\n",
    "    params = {}\n",
    "for param in params:\n",
    "    del locals()[param]\n",
    "_cur_locals = list(locals().keys())\n",
    "\n",
    "# these parameters are modifiable using papermill\n",
    "raw_folder = './data'\n",
    "out_folder = './results'\n",
    "filename = '<enter_filename_here>.h5'\n",
    "slice_idx = 0  # this is a more or less random choice, we want a slice that is somewhat in the middle\n",
    "n_coils = 12\n",
    "zs_chans = 2  # c\n",
    "zt_chans = 4  # K\n",
    "n_bases = 16  # L\n",
    "p_dropout = 0\n",
    "noise_reg = 0.05  # sigma_0\n",
    "lr_max = 1e-3  # eta_f\n",
    "lr_min = 1e-6\n",
    "lr_static_factor = 1  # eta_s / eta_f\n",
    "weight_decay = 0\n",
    "lambda_flow_spatial = 0.10  # lambda_s\n",
    "lambda_flow_temporal = 0.05  # lambda_f\n",
    "lambda_zt = 0\n",
    "lambda_basis = 0\n",
    "ksp_scale = 100\n",
    "n_iter = 10000  # N_iter\n",
    "save_every = 0\n",
    "activate_flow_after = 0  # N_def\n",
    "batch_size = 96\n",
    "cuda_num = 0\n",
    "phantom_acceleration = 8  # only used for mrxcat data\n",
    "phantom_snr = 10  # in dB, only used for mrxcat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters to dictionary\n",
    "# make sure this is the first thing after the parameters cell, but in a different cell so that it works with papermill\n",
    "params = {k: v for k, v in locals().items() if k not in _cur_locals and not k.startswith('_')}\n",
    "\n",
    "# create output folder\n",
    "output_path = Path(out_folder) / f'{Path(filename).stem}' / f'slice_{slice_idx:02d}'\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# dtype and device\n",
    "dtype = torch.float32\n",
    "device = torch.device(f'cuda:{cuda_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filename.split('.')[-1] == 'h5':\n",
    "    data = MRDDataset(Path(raw_folder) / filename, apodize=True)\n",
    "elif filename.split('.')[-1] == 'mat':\n",
    "    data = PhantomDataset(Path(raw_folder) / filename, apodize=True, acceleration_rate=phantom_acceleration, snr=phantom_snr)\n",
    "else:\n",
    "    raise ValueError('Unknown file format')\n",
    "\n",
    "# crop readout oversampling\n",
    "print('Cropping readout oversampling...')\n",
    "data.crop_readout_oversampling()\n",
    "\n",
    "# whiten k-space\n",
    "print('Whitening...')\n",
    "data.whiten()\n",
    "\n",
    "print(f'Number of slices: {data.n_slices}')\n",
    "print(f'Number of frames: {data.n_phases}')\n",
    "print(f'Number of coils:  {data.n_coils}')\n",
    "print(f'Matrix size:      {data.matrix_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select slice\n",
    "data.sl = slice_idx\n",
    "\n",
    "# undersampled k-space data\n",
    "k = data.k  # [frame, coil, kx, ky]\n",
    "\n",
    "# coil compression\n",
    "if k.shape[1] > n_coils:\n",
    "    print(f'Coil compression: {k.shape[1]} coils -> {n_coils} coils')\n",
    "    k = mri.coil_compression(k, n_coils, ch_axis=1)\n",
    "\n",
    "# sampling mask\n",
    "m = (np.abs(k) > 0).astype(np.int8)  # [frame, coil, kx, ky]\n",
    "m = m[:, 0]  # [frame, kx, ky]\n",
    "\n",
    "# physio data\n",
    "ecg = data.get_physio(0)  # [time, channel]\n",
    "ecg_t = data.get_physio_t(0)  # [time,]\n",
    "resp = data.get_physio(2)  # [time, channel]\n",
    "resp_t = data.get_physio_t(2)  # [time,]\n",
    "\n",
    "# acceleration rate\n",
    "m_tmp = m[:, m.shape[1]//2, :]\n",
    "r = m_tmp.size / m_tmp.sum()\n",
    "print(f'Acceleration rate: {r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kspace and mask\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(np.abs(k[0, 0, :, :])**0.2, cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(m[0, :, :], cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(m[:, m.shape[1]//2, :], cmap='gray')\n",
    "plt.savefig(output_path / 'kspace.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average images for compressed coils\n",
    "kspace_avg = mri.average_data(k, 0)\n",
    "img_avg = fft_np.ifftnc(kspace_avg, axes=[1, 2])\n",
    "plotting.plot_multichannel(img_avg, channel_axis=0, columns=6, figheight_per_row=3, figsize=(10, None),  # type: ignore\n",
    "                           complex='abs', save_path=output_path / 'coils_compressed.png', show=True, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coil-combined image\n",
    "img_combined = mri.rss(img_avg, 0)  # type: ignore\n",
    "plt.imshow(img_combined, cmap='gray')\n",
    "plt.savefig(output_path / 'averaged_image.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coil sensitivity estimation\n",
    "sens_maps = sigpy.mri.app.EspiritCalib(kspace_avg, calib_width=24, thresh=0.02, crop=0, show_pbar=False).run()\n",
    "assert isinstance(sens_maps, np.ndarray), 'ESPIRiT failed'\n",
    "plotting.plot_multichannel(sens_maps, channel_axis=0, columns=6, figheight_per_row=3, figsize=(10, None), complex='abs',\n",
    "                           save_path=output_path / 'sens_maps.png', show=True, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial basis generator\n",
    "basis_gen = models.UNet(\n",
    "    enc_channels=[zs_chans, 32, 64, 64, 64],\n",
    "    dec_channels=[64, 64, 64, 32, 16],\n",
    "    out_channels=2 * n_bases,\n",
    "    kernel_size=3,\n",
    "    n_convs_per_block=2,\n",
    "    p_dropout=p_dropout,\n",
    "    interpolation_mode='bilinear',\n",
    ").to(dtype=dtype)\n",
    "\n",
    "# basis coefficients generator\n",
    "coeff_gen = None\n",
    "if n_bases > 1:\n",
    "    coeff_gen = models.MLP(\n",
    "        feature_lengths=[zt_chans, 32, 64, 128, 256, 128, 64, 2 * n_bases],\n",
    "        last_activation=False,\n",
    "        p_dropout=p_dropout,\n",
    "    ).to(dtype=dtype)\n",
    "\n",
    "# required code vector size\n",
    "code_vector_size = basis_gen.required_input_size(data.matrix_size, 2)\n",
    "\n",
    "# flow generator\n",
    "unet_bottleneck_size = basis_gen.get_bottleneck_size(code_vector_size)\n",
    "flow_gen = models.FlowGenerator(\n",
    "    mlp_features=[zt_chans, 32, 64, 64, 64],\n",
    "    conv_input_size=unet_bottleneck_size,\n",
    "    conv_channels=[64, 64, 64, 64, 64],\n",
    "    n_convs_per_block=3,\n",
    "    p_dropout=p_dropout,\n",
    "    interpolation_mode='nearest',\n",
    ").to(dtype=dtype)\n",
    "\n",
    "# spatial transformer\n",
    "output_size = basis_gen.get_output_size(code_vector_size)\n",
    "transformer = models.SpatialTransformer(output_size).to(dtype=dtype)\n",
    "\n",
    "nParam = sum(p.numel() for p in basis_gen.parameters())\n",
    "print('Number of params in basis generator: %d' % nParam)\n",
    "if coeff_gen is not None:\n",
    "    nParam = sum(p.numel() for p in coeff_gen.parameters())\n",
    "    print('Number of params in coefficient generator: %d' % nParam)\n",
    "nParam = sum(p.numel() for p in flow_gen.parameters())\n",
    "print('Number of params in flow generator: %d' % nParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare k-space data\n",
    "k_tor = torch.from_numpy(k) # [frame, coil, kx, ky]\n",
    "k_max = torch.max(torch.abs(k_tor)).item()  # keep as separate variable for scaling of ground truth in quantitative evaluation of phantom data\n",
    "k_tor = k_tor * ksp_scale / k_max\n",
    "k_tor = k_tor.to(dtype=torch.promote_types(dtype, torch.complex32))\n",
    "\n",
    "# prepare mask\n",
    "m_tor = torch.from_numpy(m)[:, None]  # [frame, coil=1, kx, ky]\n",
    "m_tor = m_tor.to(dtype=dtype)\n",
    "\n",
    "# prepare sensitivity maps\n",
    "sen_tor = torch.from_numpy(sens_maps) # [coil, x, y]\n",
    "sen_tor = sen_tor.to(dtype=torch.promote_types(dtype, torch.complex32))\n",
    "\n",
    "# prepare static code vector\n",
    "zs = torch.empty(1, zs_chans, *code_vector_size, dtype=dtype).uniform_(0, 0.1)  # [batch=1, channel, x, y]\n",
    "\n",
    "# prepare temporal code vector\n",
    "zt = torch.zeros(data.n_phases, zt_chans, dtype=dtype)  # [time, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump parameterization\n",
    "with open(output_path / 'params.yaml', 'w') as f:\n",
    "    yaml.dump_all(\n",
    "        [{'params': params},\n",
    "         {'basis_gen': basis_gen.config},\n",
    "         {'coeff_gen': coeff_gen.config if coeff_gen is not None else None},\n",
    "         {'flow_gen': flow_gen.config},],\n",
    "        f,\n",
    "        explicit_start=True,\n",
    "        default_flow_style=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdip = MDIP(\n",
    "    zs=zs,\n",
    "    zt=zt,\n",
    "    basis_gen=basis_gen,\n",
    "    coeff_gen=coeff_gen,\n",
    "    flow_gen=flow_gen,\n",
    "    transformer=transformer,\n",
    "    matrix_size=data.matrix_size,\n",
    "    n_frames=data.n_phases,\n",
    "    imaging_fs=1000 / data.tres,\n",
    "    lambda_flow_spatial=lambda_flow_spatial,\n",
    "    lambda_flow_temporal=lambda_flow_temporal,\n",
    "    lambda_zt=lambda_zt,\n",
    "    lambda_basis=lambda_basis,\n",
    "    noise_reg=noise_reg,\n",
    "    lr_max=lr_max,\n",
    "    lr_min=lr_min,\n",
    "    lr_static_factor=lr_static_factor,\n",
    "    weight_decay=weight_decay,\n",
    "    output_path=output_path,\n",
    ").to_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdip.optimize(\n",
    "    k=k_tor.to(device=device),\n",
    "    sens=sen_tor.to(device=device),\n",
    "    mask=m_tor.to(device=device),\n",
    "    n_iter=n_iter,\n",
    "    save_every=save_every,\n",
    "    activate_flow_after=activate_flow_after,\n",
    "    batch_size=batch_size,\n",
    "    monitor_every=50 if isinstance(data, PhantomDataset) else -1,\n",
    "    monitor_gt=data.ground_truth[slice_idx] * ksp_scale / k_max if isinstance(data, PhantomDataset) else None,\n",
    ")\n",
    "mdip.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.semilogy(mdip.metrics['total_loss'], linewidth=0.6, label='$L$')\n",
    "plt.semilogy(mdip.metrics['kspace_loss'], linewidth=0.6, label='$L_k$')\n",
    "if lambda_flow_spatial > 0:\n",
    "    plt.semilogy(mdip.metrics['flow_loss_spatial'], linewidth=0.6, label='$L_{def,s}$')\n",
    "if lambda_flow_temporal > 0:\n",
    "    plt.semilogy(mdip.metrics['flow_loss_temporal'], linewidth=0.6, label='$L_{def,t}$')\n",
    "if lambda_zt > 0:\n",
    "    plt.semilogy(mdip.metrics['zt_loss'], linewidth=0.6, label='$L_{zt}$')\n",
    "if lambda_basis > 0:\n",
    "    plt.semilogy(mdip.metrics['basis_loss'], linewidth=0.6, label='$L_{b}$')\n",
    "plt.ylim(bottom=1e-5, top=2e0)\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.subplot(122)\n",
    "plt.semilogy(mdip.metrics['residual'], linewidth=0.6)\n",
    "plt.ylim(bottom=6e-3, top=2e0)\n",
    "plt.tight_layout()\n",
    "plt.title('Residual')\n",
    "plt.savefig(output_path / 'loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "with mdip.no_grad_and_eval():\n",
    "    cine, basis, coeffs, flow = mdip.forward_()\n",
    "    cine = cine.cpu().numpy()\n",
    "    basis = basis.cpu().numpy()\n",
    "    coeffs = coeffs.cpu().numpy()\n",
    "    flow = flow.cpu().numpy()\n",
    "\n",
    "    # scale back to original k-space\n",
    "    cine = cine / ksp_scale * k_max\n",
    "\n",
    "    # plot predicted k-space\n",
    "    kpred = fft_np.fftnc(cine[:, None] * sens_maps[None], [2, 3])  # type: ignore\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.abs(kpred[0, 0]) ** 0.2, cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.abs(cine[0]), cmap='gray')\n",
    "    plt.savefig(output_path / 'kpred.png')\n",
    "    plt.show()\n",
    "\n",
    "    # crop to recon size\n",
    "    cine = mri.center_crop(cine, data.recon_size, (1, 2))\n",
    "\n",
    "    mdip.save_cine(cine, equalize_histogram=True)\n",
    "    mdip.save_basis(basis, show=True)\n",
    "    if n_bases > 1:\n",
    "        mdip.save_coeffs(coeffs, show=True)\n",
    "    mdip.save_flow(flow)\n",
    "    ecg_t_ = (ecg_t - ecg_t.min()) / 1000\n",
    "    resp_t_ = (resp_t - resp_t.min()) / 1000\n",
    "    mdip.save_static_code_vector()\n",
    "    mdip.save_temporal_code_vector()\n",
    "    mdip.save_temporal_code_vector((ecg[:, 0], ecg_t_), (resp[:, 0], resp_t_), name='zt_ecg_resp', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L+S reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lps = LowRankPlusSparse(k_tor, sen_tor, m_tor).to_device(device)\n",
    "l, s = lps.run(max_iter=500, lambda_l=0.5, lambda_s=0.05, tol=1e-5)\n",
    "l = l.cpu().numpy()\n",
    "s = s.cpu().numpy()\n",
    "cine_lps = l + s\n",
    "cine_lps = cine_lps / ksp_scale * k_max  # scale back to original k-space\n",
    "cine_lps = mri.center_crop(cine_lps, data.recon_size, (1, 2))  # crop to recon size\n",
    "mdip.save_cine(cine_lps, name='cine_lps', equalize_histogram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only for phantom data: Quantitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(data, PhantomDataset):\n",
    "    # save ground truth vs noisy image\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(np.abs(data.ground_truth[0, 0]), cmap='gray')\n",
    "    plt.title('Ground truth')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.abs(data.noisy_img[0, 0]), cmap='gray')\n",
    "    plt.title(f'Noisy image (SNR={data.snr_db} dB)')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path / 'ground_truth_vs_noisy.png')\n",
    "    plt.close()\n",
    "\n",
    "    # save ground truth cine\n",
    "    cine_gt = data.ground_truth[slice_idx]\n",
    "    mdip.save_cine(cine_gt, name='cine_gt', equalize_histogram=True)\n",
    "\n",
    "    # save noisy cine\n",
    "    cine_noisy = data.noisy_img[slice_idx]\n",
    "    mdip.save_cine(cine_noisy, name='cine_noisy', equalize_histogram=True)\n",
    "\n",
    "    # get magnitude reconstructions\n",
    "    cine_gt = np.abs(cine_gt)\n",
    "    cine_noisy = np.abs(cine_noisy)\n",
    "    cine_mdip = np.abs(cine)\n",
    "    cine_lps_ = np.abs(cine_lps)\n",
    "\n",
    "    # quantitative evaluation\n",
    "    with open('mrxcat_annotations.yaml', 'r') as f:\n",
    "        annotations = yaml.safe_load(f)[output_path.parent.name]\n",
    "        bbox = annotations['bbox']\n",
    "        center = annotations['center']\n",
    "    preds_tuples = [('M-DIP', cine_mdip), ('LPS', cine_lps_), ('Noisy', cine_noisy)]\n",
    "    metrics_cine = evaluate.get_metrics(cine_gt, *preds_tuples)\n",
    "    metrics_roi = evaluate.get_metrics(cine_gt, *preds_tuples, bbox=bbox)\n",
    "    metrics_profiles = evaluate.get_metrics(cine_gt, *preds_tuples, center=center)\n",
    "    with pd.option_context('display.float_format', '{:.4f}'.format):\n",
    "        print('Cine:')\n",
    "        print(metrics_cine)\n",
    "        print('\\nROI:')\n",
    "        print(metrics_roi)\n",
    "        print('\\nTemporal Profiles:')\n",
    "        print(metrics_profiles)\n",
    "\n",
    "    # save metrics to csv\n",
    "    evaluate.update_metrics_csv(\n",
    "        output_path / 'metrics.csv', ('cine', metrics_cine), ('roi', metrics_roi), ('profiles', metrics_profiles),\n",
    "    )\n",
    "\n",
    "    # plot monitored metrics\n",
    "    mdip.save_metrics(show=True)\n",
    "\n",
    "    # save ROIs\n",
    "    evaluate.save_cine_roi(cine_gt, bbox, output_path / 'ROI_cine_gt.gif', data.tres)\n",
    "    evaluate.save_cine_roi(cine_mdip, bbox, output_path / 'ROI_cine_mdip.gif', data.tres)\n",
    "    evaluate.save_cine_roi(cine_lps_, bbox, output_path / 'ROI_cine_lps.gif', data.tres)\n",
    "    evaluate.save_cine_roi(cine_noisy, bbox, output_path / 'ROI_cine_noisy.gif', data.tres)\n",
    "\n",
    "    # save temporal profiles\n",
    "    evaluate.save_temporal_profiles(cine_gt, center, output_path / 'profile_cine_gt.png')\n",
    "    evaluate.save_temporal_profiles(cine_mdip, center, output_path / 'profile_cine_mdip.png')\n",
    "    evaluate.save_temporal_profiles(cine_lps_, center, output_path / 'profile_cine_lps.png')\n",
    "    evaluate.save_temporal_profiles(cine_noisy, center, output_path / 'profile_cine_noisy.png')\n",
    "\n",
    "    # save error images\n",
    "    evaluate.save_error_map(cine_gt, cine_mdip, output_path / 'error10x_mdip.gif', data.tres, scale=10)\n",
    "    evaluate.save_error_map(cine_gt, cine_lps_, output_path / 'error10x_lps.gif', data.tres, scale=10)\n",
    "    evaluate.save_error_map(cine_gt, cine_noisy, output_path / 'error10x_noisy.gif', data.tres, scale=10)\n",
    "\n",
    "    # save overview image\n",
    "    evaluate.save_overview_image(cine_gt[0], bbox, center, output_path / 'overview.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move everything back to CPU\n",
    "mdip = mdip.to_device(torch.device('cpu'))\n",
    "lps = lps.to_device(torch.device('cpu'))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgdip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
